# Управление памятью

## Введение в управление памятью

> [In Progress] адаптация курса

До сих пор мы все сидели на большой платформе .NET Framework. Многие из нас и сейчас на ней сидят и, наверняка, долго ещё будут разрабатывать используя именно её. Когда я рассказывал на предыдущих докладах как работает Garbage Collector, то весь рассказ умещался ровно в один доклад и, зачатую, мне задавали один вопрос: «Зачем это знать? Ведь работает как-то и работает». На уровне тех знаний, которые нам давали раньше и на собеседованиях, обычно говорят: есть три поколения, два хипа больших и малых объектов. Еще максимум можно услышать про наличие неких сегментов и таблицы карт. Но обычно дальше поколений и хипов люди не уходят. И все почему? И вовсе не потому, что чего-то не знают, а потому, что действительно не понятно, зачем это знать. Ведь та информация, которая нам давалась, выглядела как рекламный буклет к чему-то большому. Ну знаем мы про три поколения... Теоретически, если забить второе поколение объектами нулевого, будет проблемы. Но это, согласитесь, всё какое-то эфемерное.

Сейчас, когда Microsoft открыли исходники, я ожидал нескольких бенефитов от этого. Первый бенефит - это то, что сообщество накинется и начнет какие-то баги исправлять. Оно накинулось. И исправило все грамматические ошибки в комментариях. Много запятых исправлено. Можно даже подать на членство в .NET Foundation. Сейчас же можно: дорога открыта для граммар-наци.

Рассказ будет идти от общего к частному. Т.е. не будет такого, что мы сегодня будем плотно изучать все его алгоритмы... Да так плотно, что к концу дня головы повзрываются, а ночью будет беспокойных сон. Нет: мы будем разбираться от общего к частному, чтобы у всех пришло полное понимание.

Мы пишем разные программы: консольные, сервисы, web-сервисы и другие. Они все примерно одинаково работают. Но есть очень важное отличие - это стиль работы с памятью. Консольные приложения, скорее всего, работают в рамках базовой, выделенной при старте приложению, памяти. Такое приложение всю ее использует и больше ничего не запросит: запустилось и вышло. Иногда речь идет о сервисах, которые долго работают, перерабатывают память постоянно. И делают это не по изолированным запросам, в отличие от сервисов ASP.NET и WCF (которые мы вызвали, из базы что-то достали и забыли). Именно как какой-то расчётный сервис: есть поток данных на вход, с которыми сервис работает и так может очень долго. Как правило, это уже совершенно другой стиль расхода памяти. В этом случае память необходимо контролировать, смотреть как она расходуется, течет - не течет.

А если это ASP.NET, то это уже третий способ управления памятью. Надо понимать, что нас вызвал внешний код, мы отработаем достаточно быстро и исчезнем. И когда этот запрос пройдет, то использованную при запросе, память можно сбрасывать целиком. Это как пример.

Как же этим всем управлять? С точки зрения разработки Garbage Collector, с точки зрения системы менеджмента памяти у нас есть совершенно разные стили и мы должны в них идеально хорошо работать. У нас же может быть машина, на которой запустилось консольное приложение, а есть машина, на которой приложение забирает 256 Гб. Прежде всего, чтобы разграничить работу алгоритмов управления памятью, надо как-то классифицировать эту память. Ведь, даже если это серверное приложение, оно расходует память по-разному на разных участках.

Как можно классифицировать? Например, по размеру. Мы можем разделить память на зоны, где есть куски разного размера. Чисто интуитивно понятно, что если мы говорим о больших структурах данных, то управлять ими надо совершенно по-другому. Потому что они тяжелые и их трудно перемещать. А маленькие, соотвественно, занимают мало места, они вместе группируются, перемещать легко, однако ими тяжелее управлять. А значит, для них без всякой статистики и так понятно, что должен быть другой подход.

Если разделять по времени жизни, то тут тоже возникают идеи. Если объекты короткоживущие, то, возможно, к ним надо чаще присматриваться, чтобы побыстрее от них избавляться. Если объекты долгоживущие, то можно уже посмотреть на статистику. Если таких объектов по статистике много, то используются одни алгоритмы. Если мало, то можно представить, что возможно в эту область памяти можно смотреть реже.

Возможно, стоит разделить объекты по изменяемости. Если объект изменяем, то с ним нужен один подход, а если он не изменяем, константен, вылетает без модификаторов, то его стоит отнести к другой категории, потому что такие объекты обычно короткоживущие.

Или по типу данных. Можно легко предположить, что все типы, которые отнаследованы от атрибута, будут жить вечно. Или строки, которые представляют собой массив символов. К ним тоже может быть свой подход.

Видов может быть сколько угодно и в зависимости от классификаций может оказаться, что управление памятью для конкретной классификации может быть более эффективно, если на классификации не делить.

Когда строили GC, выбрали первые два вида классификаций: размер и время жизни (хотя если смотреть на деление класс/структура, то можно подумать, что классификации на самом деле три. Однако, различие свойств классов и структур можно свести к размеру и времени жизни).

Исходя из размера, есть две стратегии сборки мусора, а вовсе не одна, как мы ранее думали. Самая распространенная или известная - это compact, когда происходит сжатие кучи. Про sweep знают меньше, но эта стратегия наиболее эффективна. Sweep - это уборка мусора без сжатия.

Итак, мы знаем что у нас существует два способа работы с кучами. Подумаем исходя из размеров объектов. Если у нас объекты имеют большие размеры, то нам не выгодно делать compacting. Потому что в этом случае мы все объекты перетаскиваем на освободившиеся участки. То есть копируем их. А если объект огромен, то копировать дорого и compacting не выгоден.

Здесь удобен только sweep. Об этом способе мы подробно поговорим позже. Как он работает: память освобождается и свободный кусок сохраняется в список свободных участков и дальше переиспользуется.

А если объекты маленькие, то наоборот - удобен compacting. Например, у нас была куча объектов и мы потеряли ссылку на объекты через один, и получается, что занятые участки и свободные чередуются, например по 24 байта.  И может так оказаться, что такие маленькие участки нам могут больше не понадобиться, потому что дальше мы будем аллоцировать более крупные объекты. Возникнет фрагментация. Поэтому sweep с маленькими объектами не удобен. Наоборот, стоит сжать кучу. Отсюда у нас получается Small Objects Heap и Large Objects Heap: меньше 85 тысяч байт, либо больше или равно 85 тысячам байт.

Цифра странная, выведена из статистики, которая строится на стандартных приложениях. По этой статистике при установке порога в 85 тысяч байт все будет работать наиболее оптимизировано.

В Small Objects Heap объекты маленькие, поэтому используем для нее compacting. Из-за их размера можно легко и быстро заполнять образовавшиеся пустоты. То есть, мы берем и просто сжимаем. Однако, фаза планирования для SOH может решить, что в нем более выгоден sweep. Когда речь идет о SOH там оба алгоритма прекрасно работают. Там иногда включается и sweep, но по определенным сценариям, о которых мы поговорим позже.

Но LOH использует только sweep collection, при этом пользователь может вызвать сжатие LOH вручную. Это было введено не так давно.

В отличии от SOH выравнивание не зависит от платформы и равно 8 байтами в LOH. Это значит, что в SOH зависит от платформы в первую очередь. Если 32х разрядная система, то выравнивание идет по 4м байтам, а если 64х разрядная - то по восьми. В LOH без разницы - всего 8 байт. Это сделано для внутренних оптимизаций.  

Тут возникает проблема: у нас есть хип маленьких объектов и хип больших. Они, соответственно, разделены. Но по факту мы всегда аллоцируем маленькие объекты. Их в любом случае будет больше: возможно, миллионы. А значит, их надо как-то дополнительно сегментировать. GC проходит через разные стадии: стадия планирования, стадия маркировки, сбора мусора. На 200гб памяти, если так получится, стадия маркировки будет очень дорогой, а потому память надо как-то дополнительно сегментировать.

Поэтому, второй тип сегментации работает исходя из времени жизни объектов. Куча растет у нас в одном направлении. Аллокация идет с младших адресов к старшим. Берется указатель на первый свободный участок и затем он сдвигается на размер выделенного объекта и все: куча растет в одном направлении. Отсюда можно сделать вывод о том, как легко поделить на три поколения. Все, что в младших адресах - это старые объекты, где-то в середине, это первое поколения, а то, что мы выделяем сейчас - это нулевое.

Как я уже говорил, если объекты живут долго, то туда можно реже заглядывать, чтобы запускать GC. Поэтому, если мы сделаем некое скользящее окно внутри нулевого поколения, мы можем его сделать таких размеров, чтобы обходить его за гарантированно короткий промежуток времени. И Microsoft гарантирует, что нулевое поколение будет собираться за какие-то определенные миллисекунды. Т.е. GC быстро что-то сделал и дальше пошел, а никто и не заметил. И именно ради этого имеется деление на поколения.

LOH имеет другую структуру. Сюда попадает все, что больше или равно 85 тысячам байт. Цифра странная, но нам полезно ее знать.  Ее можно использовать, например, чтобы определить размер для аллоцируемого массива, чтобы он не ушел в кучу больших объектов. Если аллоцируете массив int-ов, то нужно грубо поделить на четыре и получится примерно 20 тысяч int-ов, которые туда прекрасно лягут и не уйдут в LOH. Также интересно, что в LOH уходят массивы double от тысячи элементов и выше. В Питере мне задавали вопрос, почему именно от тысячи элементов. Ответ примерно такой. Все эти метрики, так же как 85 тысяч байт и размер каждого поколения строятся на основе опыта. В Microsoft решили, что массивы типа double чаще всего используются в строго определенных сценариях. В обычных сценариях такие огромные массивы чисел с плавающих запятой никто не аллоцирует. Скорее всего это математика и если больше, то выгоднее всего это помещать в LOH помещать, и пусть оно там живет.

Проверить это все очень легко. Можно написать такой код - слайд 24:10 - и первый массив пойдет в нулевое, а второй - во второе поколение. Какие еще классификации типов существуют для GC? У нас есть две основных, которые мы только что рассмотрели. Однако, хоть эта классификация в общем смысле нам и не доступна, она нам доступна в узком смысле: классификация по типу. Все мы знаем про интернированные строки. Если мы предполагаем, что какая-то строка будет часто встречаться, то ее стоит интернировать, тогда мы сэкономим на памяти.

Как они хранятся? Если строка интернирована, то она хранится как обычная строка в куче. Но ее надо как-то найти, чтобы проверить, что точно такая же строка уже существует. Куча иногда может достигать нескольких сотен гигабайт и поиск будет очень дорогим решением. Поэтому интернированные строки хранятся отдельно (предполагается, что их будет не так много).

У каждого домена (системного или с базовым типом BaseDomain) есть внутренние таблицы, которая нам не доступны. Среди прочих существует Large Heap Handle Table. Существует два типа внутренних массивов, основанных на bucket-ах. Это массив статиков. Имеются ввиду статические члены классов, которые хранятся в массивах. У каждого домена есть ссылка на массив статиков. И дальше ячейками являются ссылки на значения. И еще одна - pinning handles. Это таблица запиненных элементов. Для тех случаев, когда вы пинуете объект в памяти, можете сделать это двумя путями. Первый - это через API, а второй - через ключевое слово fixed в C#. Это два совершенно разных механизма.

Когда вы используете pin через API, вы пинуете, создавая GC-handle структуру и помещая эту структуру в таблицу pinning handles, которую видно на экране. А когда вы используете ключевое слово fixed, то объект пинуется, только если в этот момент происходит GC. То есть, если GC произошел внутри блока fixed, тогда происходит pinning. Поэтому какой вывод: если вам нужно пиновать  - используйте fixed. Потому что в этом случае вы пиновать не будете до тех пор, пока GC не попадет в этот блок.  

Соответственно, исходя из времени жизни, из-за  большого количества объектов, SOH разделен на части, чтобы им было проще управлять. Заполнение SOH идет линейно, поэтому старые объекты живут в младших адресах, свежие - в старших. Старые объекты, как правило, живут долго. Чем дольше объект существует, тем больше вероятность того, что он будет существовать все время работы приложения. Поэтому существует три поколения. Нулевое поколение - это между временем создания объекта и ближайшим GC. Объектов не успевает накопится слишком много и GC успевает их быстро убрать, не залезая в остальную кучу.

Первое поколение живет между первым и вторым GC. Соответственно, для тех, кто не ушел во второе. Оптимизация какая: нулевое собирать быстро, первое - чуть подольше. Это последняя возможность GC собрать объект, прежде чем он ушел во второе, огромное, поколение. Если объект ушел во второе поколение, то, скорее всего, он будет жить долго. Туда можно редко обращаться. А первое - для объекта, который случайно ушел в первое поколение, но на самом деле он короткоживущий. Это такая оптимизация, чтобы его во втором не ловить. И второе поколение для тех, кто решил пожить подольше и если GC туда пришел, то он там останется работать надолго.

Оранжевые кубики - это руты. Руты - это точки, относительно которых, если обходить граф, то гарантированно вы обойдете все объекты, которыми пользуется программа. Если бы фаза маркировки работала на всех поколениях, то она бы работала долго. Поэтому она работает максимально на самых младших. Если мы решили, что собираем нулевое поколение, то она только там и будет работать. Поэтому есть три типа ссылок.  Первый тип - ссылка внутри одного поколения. Например, если мы с рута пришли в нулевое поколение, а дальше у нас ссылка из этого объекта, но опять в нулевое поколение. Это внутренняя ссылка.   Второй тип ссылок - это ссылка из более старшего поколения в более младшее поколение. Older-to-younger. Он характеризуется тем, что объект, на который мы ссылаемся из первого поколения нет имеет ссылки с рута в нулевом поколении. Это значит, что если мы будем маркировать только нулевое поколение, чтобы на нем GC отработал, то мы пропустим этот объект. Мы должны знать о существовании ссылки с более старшего поколения. 

Третий вид ссылок - это ссылка из младшего в старшее поколение. Для нас она не важна. Если мы собираем нулевое поколение  - она не имеет значение. При сборке более старших поколений, младшие тоже собираются. Почему? Если собираем, например, первое - оно больше, крупнее. И, поскольку, нулевое поколение собирается намного чаще, то есть высокая степень вероятности, что после сборки первого будет собрано и нулевое. И GC опять запустится. Для того, чтобы два раза не ходить за одним и тем же, пересобираются и более младшие поколения. В этом случае нам нужно знать ссылку из младшего в старшие? Нам это без разницы, она и так есть. При сборке второго поколения та же самая ситуация. С точки зрения фазы маркировки нам важны ссылки внутри поколения и ссылки с более старших на наше поколение.

Если мы находимся в нулевом поколении - как узнать о том, что на нас есть ссылка с более старшего поколения. Есть механизм, который в начале изучения начинает немного пугать. Есть такой код (см. слайд) 35:19.

Кстати, такие сценарии работы GC можно проверять таким способом: мы создаем объект, делаем GC.Collect(), отправляем его в первое поколение. Мы знаем, что он туда уйдет. Дальше создаем ссылку и тем самым фактически создаем ссылку из старшего поколения в младшее. Если дома захочется с чем-то поиграть, то с помощью метода GC.Collect() можно смоделировать такие ситуации.

Что мы здесь видим? У нас есть x, GC.Collect(), инстанс класса Foo уходит в поколение один из нулевого. И дальше x.field присваиваем new Boo(). Это значит, что объект типа Foo начинает ссылаться на новый инстанс объекта типа Boo. То есть из первого в нулевого. Это у нас older-to-younger link.

Что происходит в .NET. В месте присваивания, джиттер, то есть там не просто присваивание, а присваивание с проверкой. Эта техника называется Write Barrier и Remembered Set. В .NET она называется немного по-другому. Если у нас звезды сошлись, что нужно запомнить эту ссылку, то мы запоминаем ее во внутренней структуре джита.

Что это за условие? Значение - это ссылка на экземпляр .NET класса. Точка присваивания находится в управляемой куче и имеет более старшее поколение, чем адрес присваиваемого объекта. Когда мы делаем вот так (см. слайд 37:29), джиттер дополнительно проверяет, что слева поколение старше, чем справа. Если старше, то он запоминает адреса во внутренних структурах, убеждается, что с левой части на правую есть ссылка. Это нужно для дальнейшей сборки мусора. На фазе маркировки отмечается выбранное поколение и если у нас есть ссылки в Remembered Set, если мы запомнили, что где-то сохраняли ссылку из первого в нулевое поколение, они тоже становятся корнями, чтобы пройти маркировку. Но хип получается в итоге огромный и становится страшновато.

Поэтому используется более оптимизированный способ. Он называется механизм карточного стола. Знания об этом механизме не так распространены. Как он работает? Если взять адресное пространство всего огромного хипа, весь кусок памяти, то сбоку есть карточный стол. Это, грубо говоря, массив чисел. Где каждый бит массива отвечает за определенный диапазон памяти. Если бит выставлен в единицу, значит в этом диапазоне памяти есть ссылка на младшее поколение. То есть это массив признаков ссылок на младшее поколение. См. слайд - 40:12 

У нас есть память, внизу карточный стол. У нас появилась ссылка, слева на право. Это значит, что бит должен быть выставлен в единицу. Потому что от более старшего поколения пошла ссылка в более младшее.   Каждый бит карточного стола отвечает за 128 байт в x86 и за 256 байт в x64. Это, по сути, 32 машинных слова. Машинное слово - это то, с чем работает процессор.

Если учесть, что каждый пустой объект, максимально маленький (например, new Object) занимает четыре машинных слова в среднем, то получается, что один бит карточного стола перекрывает десять объектов. И если хотя бы с одного из них есть ссылка в младшее поколение, то GC должен при обходе в фазе маркировки зайти по этому адресу и просмотреть все десять объектов и найти те, которые ссылаются на младшее поколение. Один байт перекрывает уже 1,2 КБ оперативной памяти. Или 80 объектов. Четыре байта - 320 объектов. Это x86 архитектура. Получается жирновато, если ссылка появилась.

Как это работает. Можно посмотреть код, который будет вызван при присваивании (см. слайд 43:24) по этому адресу на github. Там ассемблеровский код, он достаточно простой, разобраться в нем легко. Есть много комментариев, гораздо больше, чем кода.

Реализация сильно зависит от особенностей. У нас есть Workstation GC, есть серверный GC. У Workstation есть две версии: до и после роста кучи. Как следствие, перемещается gen_1 gen_0. И Server GC: есть несколько хипов для SOH и несколько для LOH. Там свои реализации этих методов присваивания, потому что придется параметризовать для какой кучи идет вызов. А так он просто генерирует ставку для новой кучи и все хорошо. Плюс две реализации под x64. Если смотреть базовую, то будет примерно так (см. слайд 44:36). Регистр RCX - это адрес filed. Адрес таргета, куда мы присваиваем. RDX - это ссылка на объект. Когда мы присваивали, должна быть составлена эта инструкция и больше ничего. Но на самом деле нет. Присвоили и дальше этим кодом мы проверяем, находится ли правая часть присваивания внутри эфемерного сегмента (gen_0, gen_1). И если находится, то мы берем карточный стол, делим на 2048, получаем адрес ячейки и если флаг не выставлен, то выставить.

Здесь есть две особенности. Первая  - почему просто не выставить? Это будет очень долго. Операция записи намного дольше, чем чтения. Чтение происходит из кеша, а чтобы записать надо записать кроме кеша еще и в оперативную память. Поэтому их проверяем. Интересна процедура выставления флага. Он выставляется сразу же 0FF. То есть мы выставляем не один флаг, а сразу группой. Почему? Когда мы будем дальше проверять ссылку из старшего поколения в младшее, нам побитово будет долго проверять. Проще сразу словами делать проверку. Вместо того, чтобы смотреть, на каком бите ссылка и какие 2 КБ смотреть, все работает проще, система оперирует более значительными диапазонами.  

Код, получается, проверяет только поколение object, но не target. Target не интересует. Мы проверяем только то, что мы попали в нулевое или первое поколение. В любом этом случае выставляется бит в карточном столе. Когда мы проверяем нулевое поколение, будем проходится по карточному столу, который относится и к первому, и ко второму поколению. Нас устроит, что биты выставлены. Если первое поколение будем просматривать с нулевым, собирать там мусор и у первого и второго, то мы будем просматривать карточный стол второго поколения. Там тоже эти биты будут выставлены. Поэтому мы левую часть смотрим, и не имеет значения первого или второго поколения. Дальше фильтрация уже идет на стадии проверки.

Однако, карточный стол в случае большого хипа (у LOH он может быть феерических размеров) тоже будет огромным. И по нему точно так же будет идти сканирование. Мы собираем нулевое поколение и должны уложиться в несколько миллисекунд, а у нас хип в несколько сотен ГБ. Например, это сервер. Карточный стол придется сканировать весь, а это долго. Выход - двухуровневый карточный стол. Называется это Cards Bundle Table. Это еще один массив, где бит отвечает за 32 слова карт. Этот массив оперирует огромными диапазонами. Получается, 1 бит Cards Bundle Table отвечает за 128 Кб на x86 и за 256 Кб на x64. Одна ячейка  - 4 байта, это 8 Мб карт целевой памяти.

Когда мы будем делать GC, собирая нулевое поколение, надо посмотреть, что с первого и второго есть что-то полезное и далее мы уходим в Cards Bundle Table. Сканиурем, и если где-то не ноль, то переходим на карточный стол, в соответствующий его диапазон и ищем ненулевую ячейку. И потом уже переходим в нужный диапазон памяти и сканиурем объекты, которые там находятся, в поисках ссылки со старшего на младшее поколение. И только тогда мы эту ссылку добавляем в руты и маркируем все объекты, на которые эта ссылка ведет.  

Есть маленькая оптимизация для Windows. Эта система построена, в первую очередь, на архитектуре x86, где используются механизмы вирутализации памяти процессора, которая основана на страницах памяти. Она поделена на зоны, на странички. Можно выставить флаг MEM_WRITE_WATCH. Это означает, что если кто-то будет писать по заданному диапазону, то можно подписаться на обновления. Мы сделали массив и если туда кто-то будет писать, у нас будет дергаться метод из winapi. Почему мы не видим этого когда в ассемблеровском методе расстановки  карт? Когда мы записываем, выставляя карты, Windows получает нотификацию от страницы, куда мы пишем, и исходя из этого проставляет бит в Cards Bundle Table.

Базовый вывод, который можно сделать уже сейчас, основываясь на карточных столах, что если вы хотите, чтобы GC протекал быстро и как по маслу, не стоит делать ссылок из старших поколений. Не надо делать вечноживущие массивы, аллоцировать объекты и ссылки на них складывать в эти древние массивы. Но если вы так делаете, надо контролировать, чтобы эти массивы располагались рядом, чтобы их аллоцировать друг за другом. Не распределять их по памяти. Самое неудачное, что можно сделать - это иметь кучу объектов старшего поколения и по какой-то причине выставить ссылки на младшее поколение, но не группой, а вразброс через всю память. Это самый тяжелый сценарий, потому что карточный стол будет забит единицами. А GC, собирая нулевое поколение, будет вынужден проходить все второе, все первое и искать, что там добавлено. Если вы делаете ссылку из старших поколений в младшие, то необходимо эти ссылки группировать: массив, который ссылается на объект младшего поколения. Поскольку это массив, который ссылается на объекты младшего поколения, все ячейки рядом и в карточном столе в идеале это будет просто единица. Дальше мы будем изучать более подробно.
